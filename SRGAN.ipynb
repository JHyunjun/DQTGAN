{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtRZ/38qJAyQUxYYn9sTi3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/DQTGAN/blob/main/SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6r5QcT5H5jm"
      },
      "outputs": [],
      "source": [
        "# Created by Hunjun, JANG\n",
        "# Recent revision date : 23.07.15\n",
        "# DQT-GAN(Data Quality Transformation-Generative Adversarial Network)\n",
        "\n",
        "!pip install pytube\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/GAN/DQT-GAN/Data\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the Path\n",
        "! pwd"
      ],
      "metadata": {
        "id": "HkALOfaCIEqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from pytube import YouTube\n",
        "import tensorflow as tf\n",
        "from pydub import AudioSegment\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "input_sampling_rate = 8000\n",
        "output_sampling_rate = 32000\n",
        "\n",
        "# Define the SRGAN model\n",
        "def srgan_model():\n",
        "    # Generator Model\n",
        "    generator_input = layers.Input(shape=(input_sampling_rate, 1))\n",
        "    x = layers.Conv1D(64, kernel_size=3, padding='same')(generator_input)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv1D(64, kernel_size=3, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.UpSampling1D(4)(x) # 8000*4\n",
        "    generator_output = layers.Conv1D(1, kernel_size=3, padding='same')(x)\n",
        "    generator_model = tf.keras.Model(generator_input, generator_output, name='Generator')\n",
        "\n",
        "    # Discriminator Model\n",
        "    discriminator_input = layers.Input(shape=(output_sampling_rate, 1))\n",
        "    x = layers.Conv1D(64, kernel_size=3, strides=2, padding='same')(discriminator_input)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv1D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n",
        "    discriminator_model = tf.keras.Model(discriminator_input, discriminator_output, name='Discriminator')\n",
        "\n",
        "    return generator_model, discriminator_model\n",
        "\n",
        "# Define the loss and compile the models\n",
        "def compile_srgan(generator, discriminator):\n",
        "    bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "    mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "    generator_optimizer = tf.keras.optimizers.Adam()\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam()\n",
        "    return bce_loss_fn, mse_loss_fn, generator_optimizer, discriminator_optimizer\n",
        "\n",
        "# Download and preprocess the audio\n",
        "def download_and_preprocess(link):\n",
        "    # Download audio\n",
        "    youtube = YouTube(link)\n",
        "    video = youtube.streams.filter(only_audio=True).first()\n",
        "    video.download(filename='audio.mp4')\n",
        "\n",
        "    audio = AudioSegment.from_file('audio.mp4')\n",
        "    audio.export('audio.wav', format='wav')\n",
        "\n",
        "    # Load and resample audio\n",
        "    audio, sr = librosa.load('audio.wav', sr=None, offset=2*60, duration=3*60)\n",
        "    audio_8k = librosa.resample(audio, orig_sr=sr, target_sr=input_sampling_rate)\n",
        "    audio_44k = librosa.resample(audio, orig_sr=sr, target_sr=output_sampling_rate)\n",
        "\n",
        "    # Slice into 1-second clips\n",
        "    audio_8k_clips = np.array([audio_8k[i:i+input_sampling_rate] for i in range(0, len(audio_8k), input_sampling_rate)])\n",
        "    audio_44k_clips = np.array([audio_44k[i:i+output_sampling_rate] for i in range(0, len(audio_44k), output_sampling_rate)])\n",
        "\n",
        "    return audio_8k_clips, audio_44k_clips\n",
        "\n",
        "\n",
        "# Define a training step\n",
        "def train_step(generator, discriminator, bce_loss_fn, mse_loss_fn, generator_optimizer, discriminator_optimizer, input_audio, target_audio):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_audio = generator(np.expand_dims(input_audio, axis=0), training=True)\n",
        "        real_output = discriminator(np.expand_dims(target_audio, axis=0), training=True)\n",
        "        fake_output = discriminator(generated_audio, training=True)\n",
        "\n",
        "        gen_loss = mse_loss_fn(np.expand_dims(target_audio, axis=0), generated_audio) + bce_loss_fn(tf.ones_like(fake_output), fake_output)\n",
        "        disc_loss = bce_loss_fn(tf.ones_like(real_output), real_output) + bce_loss_fn(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# Define the training loop\n",
        "def train_srgan(link, epochs):\n",
        "    # Download and preprocess audio\n",
        "    audio_8k, audio_44k = download_and_preprocess(link)\n",
        "\n",
        "    # Build and compile the SRGAN model\n",
        "    generator, discriminator = srgan_model()\n",
        "    bce_loss_fn, mse_loss_fn, generator_optimizer, discriminator_optimizer = compile_srgan(generator, discriminator)\n",
        "\n",
        "    for i in range(len(audio_8k)):\n",
        "        gen_loss, disc_loss = train_step(generator, discriminator, bce_loss_fn, mse_loss_fn, generator_optimizer, discriminator_optimizer, audio_8k[i], audio_44k[i])\n",
        "        print(f'Epoch {epochs+1}/{epochs}, Clip {i+1}/{len(audio_8k)}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}')\n",
        "\n",
        "# Finally, call the training function with the YouTube link and number of epochs\n",
        "train_srgan('https://www.youtube.com/watch?v=83EzIW3MbAI', 10)\n"
      ],
      "metadata": {
        "id": "KyBGPnOtIGIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}