{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCEpNpsT/BYRVA/phJmNLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/DQTGAN/blob/main/WGANGP_VGGLOSS_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUWGImhDY9sG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torchvision.models import vgg16\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable, grad\n",
        "\n",
        "# Hyper Parameter\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "latent_dim = 100\n",
        "lambda_gp = 10\n",
        "n_critic = 5\n",
        "\n",
        "# GPU set\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Data load\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "downsample = transforms.Resize(8)\n",
        "\n",
        "dataset = datasets.CIFAR10(root='./', train = True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(dataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show Input images\n",
        "downsampled_images = downsample(images)\n",
        "print('8X8 Images')\n",
        "imshow(torchvision.utils.make_grid(downsampled_images[:3]))\n",
        "\n",
        "# Show original images\n",
        "print('Original(32X32) Images')\n",
        "imshow(torchvision.utils.make_grid(images[:3]))\n",
        "\n"
      ],
      "metadata": {
        "id": "pBXuOJnHtlj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input is 3 x 4 x 4\n",
        "            nn.ConvTranspose2d(3, 256, 2, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            # Size now is 256 x 8 x 8\n",
        "            nn.ConvTranspose2d(256, 128, 2, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            # Size now is 128 x 16 x 16\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output size is 3 x 32 x 32\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input is 3 x 32 x 32\n",
        "            nn.Conv2d(3, 256, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Size now is 128 x 16 x 16\n",
        "            nn.Conv2d(256, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Size now is 256 x 8 x 8\n",
        "            nn.Conv2d(256, 1, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1)\n",
        "\n",
        "# Pretrained VGG for perceptual loss\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        model = vgg16(pretrained=True)\n",
        "        features = model.features\n",
        "        self.to_relu_1_2 = nn.Sequential()\n",
        "        for x in range(4):\n",
        "            self.to_relu_1_2.add_module(str(x), features[x])\n",
        "        self.to_relu_1_2 = self.to_relu_1_2.eval()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        input = (input + 1) / 2\n",
        "        target = (target + 1) / 2\n",
        "        return torch.nn.functional.l1_loss(self.to_relu_1_2(input), self.to_relu_1_2(target))\n",
        "\n",
        "# WGAN-GP gradient penalty\n",
        "def gradient_penalty(critic, real, fake, device):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = alpha * real + ((1 - alpha) * fake)\n",
        "    mixed_scores = critic(interpolated_images)\n",
        "\n",
        "    gradient = grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    penalty = torch.mean((gradient_norm - 1)**2)\n",
        "    return penalty\n",
        "\n",
        "# 모델 생성\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "vgg_loss = VGGPerceptualLoss().to(device)\n",
        "\n",
        "# Optimizers\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    for i, (real, _) in enumerate(dataloader):\n",
        "        real = real.to(device)\n",
        "        real_downsampled = downsample(real).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        D_optimizer.zero_grad()\n",
        "\n",
        "        fake = G(real_downsampled)  # Use downsampled real image as input for Generator\n",
        "        real_score = D(real)\n",
        "        fake_score = D(fake)\n",
        "\n",
        "        gp = gradient_penalty(D, real, fake, device)\n",
        "        d_loss = -(torch.mean(real_score) - torch.mean(fake_score)) + lambda_gp * gp\n",
        "\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Train Generator\n",
        "        if i % n_critic == 0:\n",
        "            G_optimizer.zero_grad()\n",
        "\n",
        "            fake_score = D(fake)\n",
        "            perceptual_loss = vgg_loss(fake, real)\n",
        "            g_loss = -torch.mean(fake_score) + perceptual_loss\n",
        "\n",
        "            g_loss.backward()\n",
        "            G_optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch}/{epochs}] d_loss: {d_loss.item()} g_loss: {g_loss.item()}')\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        utils.save_image(fake.data[:25], f\"{epoch}.png\", nrow=5, normalize=True)"
      ],
      "metadata": {
        "id": "10R2PBsebTI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_start = 0\n",
        "image_end = 5\n",
        "\n",
        "# Test dataset load\n",
        "test_dataset = datasets.CIFAR10(root='./', train=False, download=True, transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Get the dataloader iterator\n",
        "data_iter = iter(test_dataloader)\n",
        "\n",
        "# Get the original images\n",
        "original_imgs = next(data_iter)[0][image_start:image_end].to(device)  # First batch\n",
        "\n",
        "# Downsample the original images to get the input images\n",
        "test_images = downsample(original_imgs.clone())\n",
        "\n",
        "def show_imgs(original_imgs):\n",
        "    # Set the generator to evaluation mode\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        # Generate images from the downsampled images\n",
        "        test_images_fake = G(test_images)\n",
        "\n",
        "    # Convert the generated images to the correct size and normalization for visualization\n",
        "    test_images_fake = (test_images_fake + 1) / 2  # Unnormalize\n",
        "    test_images_fake = test_images_fake.clamp(0, 1)  # Clamp values\n",
        "\n",
        "    # Convert the input and original images to the correct size and normalization for visualization\n",
        "    input_imgs = (test_images + 1) / 2  # Unnormalize\n",
        "    input_imgs = input_imgs.clamp(0, 1)  # Clamp values\n",
        "\n",
        "    original_imgs = (original_imgs + 1) / 2  # Unnormalize\n",
        "    original_imgs = original_imgs.clamp(0, 1)  # Clamp values\n",
        "\n",
        "    # Make the grid of images\n",
        "    grid_fake = utils.make_grid(test_images_fake, nrow=5, normalize=True).permute(1, 2, 0)\n",
        "    grid_original = utils.make_grid(original_imgs, nrow=5, normalize=True).permute(1, 2, 0)\n",
        "    grid_input = utils.make_grid(input_imgs, nrow=5, normalize=True).permute(1, 2, 0)\n",
        "\n",
        "    # Plot the original, input and generated images\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10,10))\n",
        "    axs[1].imshow(grid_input.detach().cpu().numpy())\n",
        "    axs[1].set_title(\"Input Images\")\n",
        "    axs[1].axis('off')\n",
        "    axs[2].imshow(grid_fake.detach().cpu().numpy())\n",
        "    axs[2].set_title(\"Generated Images\")\n",
        "    axs[2].axis('off')\n",
        "    axs[0].imshow(grid_original.detach().cpu().numpy())\n",
        "    axs[0].set_title(\"Original Images\")\n",
        "    axs[0].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Show the images\n",
        "show_imgs(original_imgs)\n"
      ],
      "metadata": {
        "id": "5oAMm_rGkfcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}